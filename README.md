# **DeepLearning-Interview-Awesome-2024**　![Language](https://img.shields.io/badge/language-Jupyter-orange.svg) [![License](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE.md) ![AD](https://img.shields.io/badge/深度学习-感知算法-pink.svg)


本项目涵盖了**大模型(LLMs)专题**、**计算机视觉与感知算法专题**、**深度学习基础与框架专题**、**自动驾驶、智慧医疗等行业垂域专题**、**手撕项目代码专题**、**优异开源资源推荐专题**共计6大专题模块。我们将持续整理汇总最新的面试题并详细解析这些题目，希望能成为大家斩获offer路上一份有效的辅助资料。

2024算法面试题目持续更新，具体请 follow [2024年深度学习算法与大模型面试指南](https://github.com/315386775/DeepLearing-Interview-Awesome-2024)，喜欢本项目的请右上角点个star，同时也欢迎大家一起共创该项目。

该项目是持续更新：

- 本文录入题目的原则：**高新深**，其中高是指-各大厂公司近年高频算法面试题，新是指-题目要新紧跟学术和工业界的发展，比如录入了大量大模型领域的面试题，深是指-题目要有一定的内容与深度，可以引人思考，比如面向业务场景改进的面试题；
- 目前录入列表的题目，存在部分没有答案解析的题目，或者解析内容不全的题目，我们会尽快补上所有解析；
- 目前录入列表的顺序，没有先后、频次、难度、细类别等维度信息，后续会再给予更多维度更详细的分类；

<b><summary>🏆大模型(LLMs)专题</summary></b>

| [**01. 大模型常用微调方法LORA和Ptuning的原理**](LLMs/Reference.md) |
| :------------------------------------------- |
| [**02. 介绍一下stable diffusion的原理**](LLMs/Reference.md)           | 
| [**03. 为何现在的大模型大部分是Decoder only结构**](LLMs/Reference.md)           | 
| [**04. 如何缓解 LLMs 复读机问题**](LLMs/Reference.md)           | 
| [**05. 为什么transformer中使用LayerNorm而不是BatchNorm**](LLMs/Reference.md)           | 
| [**06. Transformer为何使用多头注意力机制**](LLMs/Reference.md)           | 
| [**07. 监督微调SFT后LLM表现下降的原因**](LLMs/Reference.md)           | 
| [**08. 微调阶段样本量规模增大导致的OOM错误**](LLMs/Reference.md)           | 
| [**09. Attention计算复杂度以及如何改进**](LLMs/Reference.md)           | 
| [**10. BERT用于分类任务的优点，后续改进工作有哪些？**](LLMs/Reference.md)           | 
| [**11. SAM分割一切网络中的Promot类型以及如何输入进网络**](LLMs/Reference.md)           | 
| [**12. Transformer的层融合是如何做到的，其中Residue Network与Layer Norm如何算子融合**](LLMs/Reference.md)           | 
| [**13. 简单介绍下Transformer算法**](LLMs/Reference.md)           | 
| [**14. 在大型语言模型 (llms) 中减少幻觉的策略有哪些？**](LLMs/Reference.md)           | 
| [**15. 你能否概括介绍一下 ChatGPT 的训练过程？**](LLMs/Reference.md)           | 
| [**16. 在大型语言模型 (llms) 上下文中的标记是什么？**](LLMs/Reference.md)           | 
| [**17. Adaptive Softmax在大型语言模型中有何用处？**](LLMs/Reference.md)           | 
| [**18. 大模型微调的LORA原理及Lora怎么训练？**](LLMs/Reference.md)           | 
| [**19. lora的矩阵怎么初始化？为什么要初始化为全0？**](LLMs/Reference.md)           | 
| [**20. Stable Diffusion里是如何用文本来控制生成的？**](LLMs/Reference.md)           | 
| [**21. Stable Diffusion相比Diffusion主要解决的问题是什么？**](LLMs/Reference.md)           | 
| [**22. Diffusion每一轮训练样本选择一个随机时间步长？**](LLMs/Reference.md)           | 
| [**23. Bert的预训练任务有什么？为什么引入下一个句子预测任务？**](LLMs/Reference.md)           | 
| [**24. 领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？**](LLMs/Reference.md)           | 
| [**25. 在大型语言模型 (llms)中数据模态的对齐如何处理？**](LLMs/Reference.md)           | 
| [**26. 训练通用目标检测器常会使用多源图像进行训练，如何处理新类别歧视？**](LLMs/Reference.md)           | 
| [**27. 举例说明强化学习如何发挥作用？**](LLMs/Reference.md)           | 
| [**28. 如何理解强化学习中的奖励最大化？**](LLMs/Reference.md)           | 
| [**29. 如何提升大语言模型的Prompt泛化性？**](LLMs/Reference.md)           | 
| [**30. Instruction Tuning与Prompt tuning方法的区别？**](LLMs/Reference.md)           | 
| [**31. 知识蒸馏是将复杂模型的知识转移到简单模型的方法，针对知识蒸馏有哪些改进点？**](LLMs/Reference.md)           | 
| [**32. Transformer中的Attention计算复杂度以及如何改进？**](LLMs/Reference.md)           | 
| [**33. 进行SFT操作的时候，基座模型选用Chat还是Base?**](LLMs/Reference.md)           | 
| [**34. 开源大模型进行预训练的过程中会加入书籍、论文等数据，这部分数据如何组织与处理?**](LLMs/Reference.md)           | 



<b><summary>🍳计算机视觉与感知算法专题</summary></b>

| [**01. 人脸识别任务中，ArcFace为什么比CosFace效果好**](VisionPerception/Reference.md) |
| :------------------------------------------- |
| [**02. FCOS如何解决重叠样本，以及centerness的作用**](VisionPerception/Reference.md)           | 
| [**03. Centernet为什么可以去除NMS，以及正负样本的定义**](VisionPerception/Reference.md)           | 
| [**04. 介绍CBAM注意力**](VisionPerception/Reference.md)           | 
| [**05. 介绍mixup及其变体**](VisionPerception/Reference.md)           | 
| [**06. Yolov5的正负样本定义**](VisionPerception/Reference.md)           | 
| [**07. Yolov5的一些相关细节**](VisionPerception/Reference.md)           | 
| [**07. Yolov5与Yolov4相比neck部分有什么不同**](VisionPerception/Reference.md)           | 
| [**08. Yolov7的正负样本定义**](VisionPerception/Reference.md)           | 
| [**09. Yolov8的正负样本定义**](VisionPerception/Reference.md)           | 
| [**10. Yolov5的Foucs层和Passthrough层有什么区别**](VisionPerception/Reference.md)           | 
| [**11. DETR的检测算法的创新点**](VisionPerception/Reference.md)           | 
| [**12. CLIP的核心创新点**](VisionPerception/Reference.md)           | 
| [**13. 目标检测中旋转框IOU的计算方式**](VisionPerception/Reference.md)           | 
| [**14. 局部注意力如何实现**](VisionPerception/Reference.md)           | 
| [**15. 视觉任务中的长尾问题的常见解决方案**](VisionPerception/Reference.md)           | 
| [**16. Yolov5中的objectness的作用**](VisionPerception/Reference.md)           | 
| [**17. 匈牙利匹配方法介绍**](VisionPerception/Reference.md)           | 
| [**18. Focal loss的参数如何调，以及存在什么问题**](VisionPerception/Reference.md)           | 
| [**19. 训练一个二分类任务，其中数据有80%的标注正确，20%标注失败**](VisionPerception/Reference.md) |      |  
| [**20. 目标检测设置很多不同的anchor，能否改善小目标及非正常尺寸目标的性能，除计算速度外还存在什么问题**](VisionPerception/Reference.md) |      |  
| [**21. Anchor-free的target assign怎么解决多个目标中心点位置比较靠近的问题**](VisionPerception/Reference.md) |      |  
| [**22. 如果在分类任务中几个类别有重叠（类间差异小）怎么办，如何设计网络结构**](VisionPerception/Reference.md) |      |  
| [**23. 在目标Crowded的场景下，经常在两个真正目标中间会出现误检的原因?**](VisionPerception/Reference.md) |      |  
| [**24. 在Unet网络结构中，四次降采样对于分割网络到底是不是必须的？**](VisionPerception/Reference.md) |      |  
| [**25. 为什么UNet++可以被剪枝，怎么去决定剪多少？**](VisionPerception/Reference.md) |      |  
| [**26. 在A场景下进行目标的标记及训练，如何在B场景下取得好的效果？**](VisionPerception/Reference.md) |      |  
| [**27. 如何修改Yolov5目标检测，从而实现旋转目标检测？**](VisionPerception/Reference.md) |      |  
| [**28. ViT、DEIT是如何处理变长序列输入的？**](VisionPerception/Reference.md) |      |  
| [**29. Transformer的注意力机制常用softmax函数，可以使用sigmoid代替吗？**](VisionPerception/Reference.md) |      |  
| [**30. VIT中对输入图像的处理是如何将patch变化为token的？**](VisionPerception/Reference.md) |      |  
| [**31. VIT直接用于分割检测等预测密集型的任务上存在什么问题？**](VisionPerception/Reference.md) |      |  
| [**32. DETR用二分图匹配实现label assignment，简述其过程**](VisionPerception/Reference.md) |      |  
| [**33. 有哪些可以解决目标检测中正负样本不平衡问题的方法**](VisionPerception/Reference.md) |      |  
| [**34. ORB特征提取的缺陷及如何进行改进**](VisionPerception/Reference.md) |      |  
| [**35. SAM在本地的模型推理效果明显差于线上web版本，有什么方式可以优化其效果？**](VisionPerception/Reference.md) |      |  
| [**36. 目标检测如何选取正负样本将会极大的影响最后的检测效果，举例ATSS如何处理的？**](VisionPerception/Reference.md) |      |  
| [**37. Anchor-Based检测器在正负样本标签分配阶段，如何去除对anchor的依赖？**](VisionPerception/Reference.md) |      |  
| [**38. 在CNN网络中，更大的核是否可以取得更高的精度？**](VisionPerception/Reference.md) |      |  
| [**39. 在轻量化模型中，举例一些从参数量、浮点运算量、模型推理时延进行优化的代表模型？**](VisionPerception/Reference.md) |      |  


<b><summary>⏰深度学习基础与框架专题</summary></b>

| [**01. 卷积和BN如何融合提升推理速度**](DeepLearning/Reference.md) |
| :------------------------------------------- |
| [**02. 多卡BN如何处理**](DeepLearning/Reference.md) | 
| [**03. TensorRT为什么能让模型跑更快**](DeepLearning/Reference.md) | 
| [**04. 损失函数的应用-合页损失**](DeepLearning/Reference.md) | 
| [**05. Pytorch DataLoader的主要参数有哪些**](DeepLearning/Reference.md) | 
| [**06. 神经网络引入注意力机制后效果降低的原因**](DeepLearning/Reference.md) |  
| [**07. 为什么交叉熵可以作为损失函数**](DeepLearning/Reference.md) |  
| [**08. 优化算法之异同 SGD/AdaGrad/Adam**](DeepLearning/Reference.md) |  
| [**09. 有哪些权重初始化的方法**](DeepLearning/Reference.md) |  
| [**10. MMengine的一些特性**](DeepLearning/Reference.md) |  
| [**11. Modules的一些属性问题**](DeepLearning/Reference.md) |  
| [**12. 激活函数的对比与优缺点**](DeepLearning/Reference.md) |  
| [**13. Transformer/CNN/RNN的时间复杂度对比**](DeepLearning/Reference.md) |  
| [**14. 深度可分离卷积**](DeepLearning/Reference.md) |  
| [**15. CNN和MLP的区别**](DeepLearning/Reference.md) |  
| [**16. MMCV中Hook机制简介及创建一个新的Hook**](DeepLearning/Reference.md) | 
| [**17. 深度学习训练中如何区分错误样本和难例样本**](DeepLearning/Reference.md)           |  
| [**18. PyTorch 节省显存的常用策略**](DeepLearning/Reference.md)           |  
| [**19. 深度学习模型训练时的Warmup预热学习率作用**](DeepLearning/Reference.md)           |  
| [**20. MMdetection中添加一个自定义的backbone网络，需要改哪些代码**](DeepLearning/Reference.md)           |  
| [**21. PyTorch中的 ModuleList 和 Sequential的区别和使用场景**](DeepLearning/Reference.md)           |  
| [**22. 考虑一个filter[-1 -1 -1; 0 0 0; 1 1 1] 用于卷积。该滤波器将从输入图像中提取哪些边缘**](DeepLearning/Reference.md)           |  
| [**23. 深度学习中为什么不对 bias 偏置进行正则化？**](DeepLearning/Reference.md)           |  
| [**24. 正则化为什么可以增加模型泛化能力**](DeepLearning/Reference.md)           |  
| [**25. 深度学习模型中如何融入传统图像处理的特征？直接拼接融合有什么问题？**](DeepLearning/Reference.md)           |  
| [**26. 多任务学习中各个任务损失的权重应该如何设计呢？**](DeepLearning/Reference.md)           |  
| [**27. 为什么Adam常常打不过SGD？症结点与改善方案？**](DeepLearning/Reference.md)           |  
| [**28. 如何处理不平衡的数据集？**](DeepLearning/Reference.md)           |  
| [**29. Pytorch代码中如何尽量避免.to(device)的操作？**](DeepLearning/Reference.md)           |  
| [**30. Pytorch中nn.Identity()/torch.chunk/torch.masked_select/torch.gather操作的应用场景？**](DeepLearning/Reference.md)           |  


<b><summary>🛺自动驾驶、智慧医疗等行业垂域专题</summary></b>

| [**01. 相机内参和外参的含义？如果将图像放大两倍，内外参如何变化？**](IndustryAlgorithm/Reference.md) |
| :------------------------------------------- |
| [**02. 坐标系的变换**](IndustryAlgorithm/Reference.md) |
| [**03. 放射变换与逆投影变换分别是什么**](IndustryAlgorithm/Reference.md) |      |  
| [**04. 卡尔曼滤波Q和R怎么调**](IndustryAlgorithm/Reference.md) |      |  
| [**05. 如何理解BEV空间及生成BEV特征**](IndustryAlgorithm/Reference.md) |      |  
| [**06. 如何在标注存在错误的数据上训练模型**](IndustryAlgorithm/Reference.md) |      |  
| [**07. 视频与图像中的目标检测具体有什么区别**](IndustryAlgorithm/Reference.md) |      |  
| [**08. 栏杆检测为什么不用网络学习**](IndustryAlgorithm/Reference.md) |      |  
| [**09. 卡尔曼滤波怎么用同一个filter同时适配车辆横穿的场景**](IndustryAlgorithm/Reference.md) |      |  
| [**10. BEV特征怎么进行数据增强**](IndustryAlgorithm/Reference.md) |      |  
| [**11. 辅助驾驶场景中，模型对60米之内的中大目标预测的bbox坐标不稳定，有较大的抖动问题，导致测距不稳定，怎么解决？**](IndustryAlgorithm/Reference.md) |      |  
| [**12. 辅助驾驶场景中，对公交站、房屋顶等特定背景误检，怎么解决？**](IndustryAlgorithm/Reference.md) |      |  
| [**13. 辅助驾驶场景中，大于100m的车辆车型分类出现跳动怎么解决？**](IndustryAlgorithm/Reference.md) |      |  
| [**14. 医学影像由于标注专业性差异，出现多人标注不一致情况怎么解决？如何用算法的方式减少误差？**](IndustryAlgorithm/Reference.md) |      |  
| [**15. NLP中给定当前query和历史query以及对应实体，如何对当前query的实体进行建模？**](IndustryAlgorithm/Reference.md)           | 
| [**16. 解释KF中的噪声矩阵含义。运动方程中估计噪声是变大还是变小？修正方程中估计噪声是变大还是变小？**](IndustryAlgorithm/Reference.md)           | 
| [**17. 举出几种光流方法，说明LK光流的建模方式？**](IndustryAlgorithm/Reference.md)           | 
| [**18. 如何在数据量十分有限，但特征数量极多的情况下选出一套合适的特征组合？**](IndustryAlgorithm/Reference.md)           | 
| [**19. SAM的点提示和框提示输入尺寸，框提示是否支持多个框？**](IndustryAlgorithm/Reference.md)           | 
| [**20. 车道线检测的任务通常采用分割方案，如何将方案降级至检测，甚至是车道线分类？**](IndustryAlgorithm/Reference.md)           | 
| [**21. 车道线检测的任务中如何处理异行线，比如道路交叉口？**](IndustryAlgorithm/Reference.md)           | 
| [**22. 为什么 larger batch size 对对比学习的影响比对监督学习的影响要大？**](IndustryAlgorithm/Reference.md)           | 
| [**23. 银行经理收到一个数据集，其中包含数千名申请贷款的申请人的记录。AI算法如何帮助经理了解他可以批准哪些贷款？**](IndustryAlgorithm/Reference.md)           | 
| [**24. 简述BEVformer的Decoder逻辑？**](IndustryAlgorithm/Reference.md)           | 
| [**25. BEVFormer中的Spatial Cross-Attention的步骤？**](IndustryAlgorithm/Reference.md)           | 
| [**26. 车上多个摄像头图像投影到2D平面如何实现？**](IndustryAlgorithm/Reference.md)           | 
| [**27. 假如你的车子有4个激光雷达，你如何设计点云分割算法？**](IndustryAlgorithm/Reference.md)           | 
| [**28. 假如当前需要你把场景里的砖头分割出来，靠点云分割能否正确识别？**](IndustryAlgorithm/Reference.md)           | 
| [**29. 点云中的水雾怎么去除？**](IndustryAlgorithm/Reference.md)           | 



<b><summary>🏳‍🌈手撕项目代码专题</summary></b>

| [**01. Pytorch实现注意力机制、多头注意力**](CodeAnything/Reference.md) |
| :------------------------------------------- |
| [**02. Numpy广播机制实现矩阵间L2距离的计算**](CodeAnything/Reference.md) | 
| [**03. Conv2D卷积的Python和C++实现**](CodeAnything/Reference.md) |      |  
| [**04. Numpy实现bbox_iou的计算**](CodeAnything/Reference.md) |      |  
| [**05. Numpy实现Focalloss**](CodeAnything/Reference.md) |      |  
| [**06. Python实现非极大值抑制nms、softnms**](CodeAnything/Reference.md) |      |  
| [**07. Python实现BN批量归一化**](CodeAnything/Reference.md) |      |  
| [**08. Pytorch手写Conv+Bn+Relu，及如何合并**](CodeAnything/Reference.md) |      |  
| [**09. 描述图像resize的过程并实现**](CodeAnything/Reference.md) |      |  
| [**10. PyTorch卷积与BatchNorm的融合**](CodeAnything/Reference.md) |      |  
| [**11. 分割网络损失函数Dice Loss代码实现**](CodeAnything/Reference.md) |      |  
| [**12. Numpy实现一个函数来计算两个向量之间的余弦相似度**](CodeAnything/Reference.md) |      |  
| [**13. Numpy实现Sigmoid函数**](CodeAnything/Reference.md) |      |  


<b><summary>🚩优异开源资源推荐专题</summary></b>

| [**01. 多个优异的数据结构与算法项目推荐**](AwesomeProjects/Reference.md) |
| :------------------------------------------- |
| [**02. 大模型岗位面试总结：共24家，9个offer**](AwesomeProjects/Reference.md)           |  
| [**03. 视觉检测分割一切源码及在线Demo**](AwesomeProjects/Reference.md)           |  
| [**04. 动手学深度学习Pytorch**](AwesomeProjects/Reference.md)           |  
| [**05. 一种用于保存、搜索、访问、探索和与您喜爱的所有网站、文档和文件聊天的工具**](AwesomeProjects/Reference.md)           |  
| [**06. 收集一些免费的ChatGPT镜像站点**](AwesomeProjects/Reference.md)           |  
| [**07. 关于大型语言模型(LLM)的一切**](AwesomeProjects/Reference.md)           |  
| [**08. 深度学习调优指南中文版**](AwesomeProjects/Reference.md)           |  
| [**09. 多模态大型语言模型的最新论文和数据集集锦**](AwesomeProjects/Reference.md)           |  
| [**10. ChatPaper：ChatGPT来加速科研流程的工具**](AwesomeProjects/Reference.md)           |  
| [**11. 消费级硬件上进行LLaMA的微调**](AwesomeProjects/Reference.md)           |  
| [**12. Stability AI提供的一系列生成模型**](AwesomeProjects/Reference.md)           |  
| [**13. 自监督方式学习强大视觉特征的框架DINOv2**](AwesomeProjects/Reference.md)           |  
| [**14. 快速的场景分割FastSAM**](AwesomeProjects/Reference.md)           |  






